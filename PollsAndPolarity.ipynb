{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Prior to the creation of this notebook, tweets were gathered using [GetOldTweets3](https://pypi.org/project/GetOldTweets3/). This was accomplished using the shell scripts found in the /shellscripts folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyData\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vader sentiment analyzer from NLTK\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics library\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn imports for ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "I defined three functions to streamline the process of gathering and analyzing sentiment polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get mean, median, min, max, and standard deviation of input\n",
    "def get_stats(info):\n",
    "    me = stat.mean(info)\n",
    "    med = stat.median(info)\n",
    "    mini = min(info)\n",
    "    maxi = max(info)\n",
    "    sdev = stat.stdev(info)\n",
    "    \n",
    "    return me,med,mini,maxi,sdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment polarities\n",
    "def get_sentiment(tweets):\n",
    "    # Lists for each category of sentiment polarity\n",
    "    neg = [] # negative\n",
    "    pos = [] # positive\n",
    "    neu = [] # neutral\n",
    "    \n",
    "    # Run the sentiment intensity analysis for input\n",
    "    for t in tweets:\n",
    "        # Get polarity scores for each tweet\n",
    "        tmp_sia = analyzer.polarity_scores(t)\n",
    "        # Variable assignment for the negative, positive, \n",
    "        # and neutral scores\n",
    "        tmp_neg = tmp_sia['neg']\n",
    "        tmp_pos = tmp_sia['pos']\n",
    "        tmp_neu = tmp_sia['neu']\n",
    "        \n",
    "        # Append each tweet's neg, pos,and neu scores to\n",
    "        # their respective lists\n",
    "        neg.append(tmp_neg)\n",
    "        pos.append(tmp_pos)\n",
    "        neu.append(tmp_neu)\n",
    "    \n",
    "    # Return the lists\n",
    "    return neg,pos,neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function to take in tweets from each date, get\n",
    "the sentiment scores, and get summary statistics \n",
    "from those sentiment scores.'''\n",
    "\n",
    "def namedate(namedate):\n",
    "    # Create a list of lists for sentiments\n",
    "    tmp = [get_sentiment(namedate)]\n",
    "    # Get summary stats \n",
    "    tmp_neg = get_stats(tmp[0][0])\n",
    "    tmp_pos = get_stats(tmp[0][1])\n",
    "    tmp_neu = get_stats(tmp[0][2])\n",
    "    # Make a list of lists for all summary stats\n",
    "    tmp_sents = [tmp_neg,tmp_pos,tmp_neu]\n",
    "    # Convert to numpy array\n",
    "    sents = np.array(tmp_sents)\n",
    "    # Return the converted numpy array\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "There are 9 different dates being analyzed and each candidate has one .csv file per date. After using Pandas to read in the .csv files, I consolidated all input into one array per candidate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden0808 = pd.read_csv('csv/biden0808.csv')['text']\n",
    "biden0815 = pd.read_csv('csv/biden0815.csv')['text']\n",
    "biden0827 = pd.read_csv('csv/biden0827.csv')['text']\n",
    "biden0907 = pd.read_csv('csv/biden0907.csv')['text']\n",
    "biden0911 = pd.read_csv('csv/biden0911.csv')['text']\n",
    "biden0912 = pd.read_csv('csv/biden0912.csv')['text']\n",
    "biden0917 = pd.read_csv('csv/biden0917.csv')['text']\n",
    "biden0921 = pd.read_csv('csv/biden0921.csv')['text']\n",
    "biden0924 = pd.read_csv('csv/biden0924.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidens = [biden0808,biden0815,biden0827,biden0907,biden0911,biden0912,biden0917,biden0921,biden0924]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders0808 = pd.read_csv('csv/sanders0808.csv')['text']\n",
    "sanders0815 = pd.read_csv('csv/sanders0815.csv')['text']\n",
    "sanders0827 = pd.read_csv('csv/sanders0827.csv')['text']\n",
    "sanders0907 = pd.read_csv('csv/sanders0907.csv')['text']\n",
    "sanders0911 = pd.read_csv('csv/sanders0911.csv')['text']\n",
    "sanders0912 = pd.read_csv('csv/sanders0912.csv')['text']\n",
    "sanders0917 = pd.read_csv('csv/sanders0917.csv')['text']\n",
    "sanders0921 = pd.read_csv('csv/sanders0921.csv')['text']\n",
    "sanders0924 = pd.read_csv('csv/sanders0924.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanderss = [sanders0808,sanders0815,sanders0827,sanders0907,sanders0911,sanders0912,sanders0917,sanders0921,sanders0924]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren0808 = pd.read_csv('csv/warren0808.csv')['text']\n",
    "warren0815 = pd.read_csv('csv/warren0815.csv')['text']\n",
    "warren0827 = pd.read_csv('csv/warren0827.csv')['text']\n",
    "warren0907 = pd.read_csv('csv/warren0907.csv')['text']\n",
    "warren0911 = pd.read_csv('csv/warren0911.csv')['text']\n",
    "warren0912 = pd.read_csv('csv/warren0912.csv')['text']\n",
    "warren0917 = pd.read_csv('csv/warren0917.csv')['text']\n",
    "warren0921 = pd.read_csv('csv/warren0921.csv')['text']\n",
    "warren0924 = pd.read_csv('csv/warren0924.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "warrens = [warren0808,warren0815,warren0827,warren0907,warren0911,warren0912,warren0917,warren0921,warren0924]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation and Analysis\n",
    "\n",
    "The namedate function runs both the get_stats() and get_sentiment() functions, for summary statistics and for sentiment polarity scores, respectively. Then it returns a Numpy array of the summary statistics for all sentiment scores, separated by date. For each candidate, I used a list comprehension to apply the namedate function to each collection of 100 tweets. \n",
    "\n",
    "After this, I reshaped the arrays to have 9 rows, each with 15 items. The original shape was 9,3,5 because the negative, positive, and neutral arrays were still individually separated. To illustrate this point, I am displaying both the sizes of biden_stats (original) and the reshaped biden_np below, followed by the first item in each array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_stats = [namedate(b) for b in bidens]\n",
    "biden_np = np.array(biden_stats).reshape(9,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 3, 5), (9, 15))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(biden_stats).shape, biden_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12768   , 0.125     , 0.        , 0.636     , 0.12656079],\n",
       "       [0.07823   , 0.05      , 0.        , 0.333     , 0.09125797],\n",
       "       [0.79403   , 0.817     , 0.312     , 1.        , 0.14131578]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12768   , 0.125     , 0.        , 0.636     , 0.12656079,\n",
       "       0.07823   , 0.05      , 0.        , 0.333     , 0.09125797,\n",
       "       0.79403   , 0.817     , 0.312     , 1.        , 0.14131578])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren_stats = [namedate(w) for w in warrens]\n",
    "warren_np = np.array(warren_stats).reshape(9,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders_stats = [namedate(s) for s in sanderss]\n",
    "sanders_np = np.array(sanders_stats).reshape(9,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour: Gather data for Tableau visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists to hold positive and negative means\n",
    "b_neg_means = []\n",
    "b_pos_means = []\n",
    "w_neg_means = []\n",
    "w_pos_means = []\n",
    "s_neg_means = []\n",
    "s_pos_means = []\n",
    "\n",
    "for i in range(0,9):\n",
    "    # Index the 2D list to get the 1st and 6th items\n",
    "    # The mean negative scores are always 1st and the mean positive\n",
    "    # scores are always 6th\n",
    "    b_neg_means.append(biden_np[i][0])\n",
    "    b_pos_means.append(biden_np[i][5])\n",
    "    w_neg_means.append(warren_np[i][0])\n",
    "    w_pos_means.append(warren_np[i][5])\n",
    "    s_neg_means.append(sanders_np[i][0])\n",
    "    s_pos_means.append(sanders_np[i][5])\n",
    "\n",
    "# Create DataFrames so that they can be written to csv files using Pandas\n",
    "b_means_df = pd.DataFrame([b_neg_means,b_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24'],\n",
    "                       index=['Negative','Positive'])\n",
    "w_means_df = pd.DataFrame([w_neg_means,w_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24'],\n",
    "                       index=['Negative','Positive'])\n",
    "s_means_df = pd.DataFrame([s_neg_means,s_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24'],\n",
    "                       index=['Negative','Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing Pandas DataFrames to csv files for Tableau\n",
    "b_means_df.to_csv('b_means.csv')\n",
    "w_means_df.to_csv('w_means.csv')\n",
    "s_means_df.to_csv('s_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate Poll Order\n",
    "\n",
    "The poll orderings are as follows:\n",
    "\n",
    "* August 8 via SurveyUSA: \n",
    "    Biden, Sanders, Warren\n",
    "    \n",
    "* August 15 order for likely voters via Fox News: \n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* August 27 LV via Emerson College: \n",
    "    Biden, Sanders, Warren\n",
    "    \n",
    "* September 7 LV via Suffolk University: \n",
    "    Biden, Sanders, Warren \n",
    "    \n",
    "* September 11 via RKM Research and Communications Inc.: \n",
    "    Sanders, Biden, Warren\n",
    "    \n",
    "* September 12 LV via YouGov: \n",
    "    Biden, Warren, Sanders \n",
    "    \n",
    "* September 17 LV via NBC News/Wall Street Journal: \n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* September 21 LV via Selzer and Co: \n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* September 24 LV via Monmouth University: \n",
    "    Warren, Biden, Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One array per candidate in chronological order\n",
    "# 0 = 1st place; 1 = 2nd place; 2 = 3rd place\n",
    "\n",
    "b_target = np.array([0,0,0,0,1,0,0,1,1])\n",
    "s_target = np.array([1,2,1,1,0,2,2,2,2])\n",
    "w_target = np.array([2,1,2,2,2,1,1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a train/test split for each candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BX_train, BX_test, by_train, by_test = train_test_split(biden_np, b_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_train, WX_test, wy_train, wy_test = train_test_split(warren_np, w_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SX_train, SX_test, sy_train, sy_test = train_test_split(sanders_np, s_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = GaussianNB()\n",
    "clf_linsvc = LinearSVC()\n",
    "clf_dt = tree.DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=3)\n",
    "clf_nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "One problem I ran into here is that, for Sanders and Warren, 3-fold cross validation generates a warning because the least-populated class has fewer than 3 items. I originally adjusted for this warning by using 2-fold validation for Warren and none for Sanders, but the accuracy was better when I proceeded with 3-fold despite the warning message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_crossval = [stat.mean(cross_val_score(clf_nb, biden_np, b_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, biden_np, b_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, biden_np, b_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, biden_np, b_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, biden_np, b_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.666667\n",
       "Linear SVC                             0.666667\n",
       "Decision Tree                          0.666667\n",
       "K-Nearest Neighbors                    0.666667\n",
       "Neural Network                         0.666667"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(b_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "s_crossval = [stat.mean(cross_val_score(clf_nb, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, sanders_np, s_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.222222\n",
       "Linear SVC                             0.555556\n",
       "Decision Tree                          0.083333\n",
       "K-Nearest Neighbors                    0.166667\n",
       "Neural Network                         0.388889"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "w_crossval = [stat.mean(cross_val_score(clf_nb, warren_np, w_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, warren_np, w_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, warren_np, w_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, warren_np, w_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, warren_np, w_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.611111\n",
       "Linear SVC                             0.361111\n",
       "Decision Tree                          0.250000\n",
       "K-Nearest Neighbors                    0.361111\n",
       "Neural Network                         0.444444"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(w_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the best performing classifiers are Naive Bayes, Linear SVC, and the Neural Network, while the worst performing classifier overall was the Decision Tree model.\n",
    "\n",
    "* Biden: all models apart from Decision Tree perform similarly.\n",
    "* Sanders: Linear SVC outperforms all other models, followed by the Neural Network. Naive Bayes did not perform well here.\n",
    "* Warren: Naive Bayes outperforms all other models, followed by the Neural Network. KNN and Linear SVC are tied for third best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(BX_train,by_train)\n",
    "predict_lin_b = clf_linsvc.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_lin_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(BX_train,by_train)\n",
    "predict_nb_b = clf_nb.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_nb_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(BX_train,by_train)\n",
    "predict_nn_b = clf_nn.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_nn_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [3, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(SX_train,sy_train)\n",
    "predict_lin_s = clf_linsvc.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_lin_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [3, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(SX_train,sy_train)\n",
    "predict_nb_s = clf_nb.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_nb_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [3, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(SX_train,sy_train)\n",
    "predict_nn_s = clf_nn.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_nn_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(WX_train,wy_train)\n",
    "predict_lin_w = clf_linsvc.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_lin_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(WX_train,wy_train)\n",
    "predict_nb_w = clf_nb.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_nb_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(WX_train,wy_train)\n",
    "predict_nn_w = clf_nn.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_nn_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation findings\n",
    "None of the learning algorithms perform particularly well, indicating that there is not a strong link between Twitter sentiment and opinion polls. The two populations have mostly different opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Although the populations do not agree well (and thus, any predictions based on a relationship between the two populations are not particularly reliable), I thought it was worth generating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction consensus\n",
    "\n",
    "The consensus of the predictions are Biden 1st, Sanders 2nd, and Warren 3rd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
