{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This project was started because I was curious how different populations view the top three Democratic presidential candidates. Joe Biden, Bernie Sanders, and Elizabeth Warren consistently poll as the top three, but not always in the same order. \n",
    "Prior to the creation of this notebook, tweets were gathered using [GetOldTweets3](https://pypi.org/project/GetOldTweets3/). This was accomplished using the shell scripts found in the /shellscripts folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "Below are the library imports, functions, and data imports that make this project possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyData\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vader sentiment analyzer from NLTK\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics library\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn imports for ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "I defined three functions to streamline the process of gathering and analyzing sentiment polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get mean, median, min, max, and standard deviation of input\n",
    "def get_stats(info):\n",
    "    me = stat.mean(info)\n",
    "    med = stat.median(info)\n",
    "    mini = min(info)\n",
    "    maxi = max(info)\n",
    "    sdev = stat.stdev(info)\n",
    "    \n",
    "    return me,med,mini,maxi,sdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment polarities\n",
    "def get_sentiment(tweets):\n",
    "    # Lists for each category of sentiment polarity\n",
    "    neg = [] # negative\n",
    "    pos = [] # positive\n",
    "    neu = [] # neutral\n",
    "    \n",
    "    # Run the sentiment intensity analysis for input\n",
    "    for t in tweets:\n",
    "        # Get polarity scores for each tweet\n",
    "        tmp_sia = analyzer.polarity_scores(t)\n",
    "        # Variable assignment for the negative, positive, \n",
    "        # and neutral scores\n",
    "        tmp_neg = tmp_sia['neg']\n",
    "        tmp_pos = tmp_sia['pos']\n",
    "        tmp_neu = tmp_sia['neu']\n",
    "        \n",
    "        # Append each tweet's neg, pos,and neu scores to\n",
    "        # their respective lists\n",
    "        neg.append(tmp_neg)\n",
    "        pos.append(tmp_pos)\n",
    "        neu.append(tmp_neu)\n",
    "    \n",
    "    # Return the lists\n",
    "    return neg,pos,neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function to take in tweets from each date, get\n",
    "the sentiment scores, and get summary statistics \n",
    "from those sentiment scores.'''\n",
    "\n",
    "def namedate(namedate):\n",
    "    # Create a list of lists for sentiments\n",
    "    tmp = [get_sentiment(namedate)]\n",
    "    # Get summary stats \n",
    "    tmp_neg = get_stats(tmp[0][0])\n",
    "    tmp_pos = get_stats(tmp[0][1])\n",
    "    tmp_neu = get_stats(tmp[0][2])\n",
    "    # Make a list of lists for all summary stats\n",
    "    tmp_sents = [tmp_neg,tmp_pos,tmp_neu]\n",
    "    # Convert to numpy array\n",
    "    sents = np.array(tmp_sents)\n",
    "    # Return the converted numpy array\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "There are 13 different dates being analyzed and each candidate has one .csv file per date. After using Pandas to read in the .csv files, I consolidated all input into one array per candidate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden0808 = pd.read_csv('csv/biden0808.csv')['text']\n",
    "biden0815 = pd.read_csv('csv/biden0815.csv')['text']\n",
    "biden0827 = pd.read_csv('csv/biden0827.csv')['text']\n",
    "biden0907 = pd.read_csv('csv/biden0907.csv')['text']\n",
    "biden0911 = pd.read_csv('csv/biden0911.csv')['text']\n",
    "biden0912 = pd.read_csv('csv/biden0912.csv')['text']\n",
    "biden0917 = pd.read_csv('csv/biden0917.csv')['text']\n",
    "biden0921 = pd.read_csv('csv/biden0921.csv')['text']\n",
    "biden0924 = pd.read_csv('csv/biden0924.csv')['text']\n",
    "biden0929 = pd.read_csv('csv/biden0929.csv')['text']\n",
    "biden1003 = pd.read_csv('csv/biden1003.csv')['text']\n",
    "biden1007 = pd.read_csv('csv/biden1007.csv')['text']\n",
    "biden1016 = pd.read_csv('csv/biden1016.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Obama Endorses Justin Trudeau. He Still Hasnâ€™t Endorsed Joe Biden - https://go.shr.lc/35E6gEF'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden1016[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidens = [biden0808,biden0815,biden0827,biden0907,biden0911,biden0912,biden0917,biden0921,biden0924,biden0929,biden1003,biden1007,biden1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders0808 = pd.read_csv('csv/sanders0808.csv')['text']\n",
    "sanders0815 = pd.read_csv('csv/sanders0815.csv')['text']\n",
    "sanders0827 = pd.read_csv('csv/sanders0827.csv')['text']\n",
    "sanders0907 = pd.read_csv('csv/sanders0907.csv')['text']\n",
    "sanders0911 = pd.read_csv('csv/sanders0911.csv')['text']\n",
    "sanders0912 = pd.read_csv('csv/sanders0912.csv')['text']\n",
    "sanders0917 = pd.read_csv('csv/sanders0917.csv')['text']\n",
    "sanders0921 = pd.read_csv('csv/sanders0921.csv')['text']\n",
    "sanders0924 = pd.read_csv('csv/sanders0924.csv')['text']\n",
    "sanders0929 = pd.read_csv('csv/sanders0929.csv')['text']\n",
    "sanders1003 = pd.read_csv('csv/sanders1003.csv')['text']\n",
    "sanders1007 = pd.read_csv('csv/sanders1007.csv')['text']\n",
    "sanders1016 = pd.read_csv('csv/sanders1016.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanderss = [sanders0808,sanders0815,sanders0827,sanders0907,sanders0911,sanders0912,sanders0917,sanders0921,sanders0924,sanders0929,sanders1003,sanders1007,sanders1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BREAKING NEWS FROM WASHINGTON DC QUESTIONS NEED TO BE ANSWERED REGARDING MIKE PENCE AN CAIR MUSLIM BROTHERHOOD WHY WOULD MIKE PENCE BRING SOMEONE TO WASHINGTON DC TIED TO JOE BIDEN.. BERNIE SANDERS.. PLUS THEY HATE PRESIDENT TRUMP. THE QUESTION IS WHY \\u2066 @realDonaldTrump\\u2069pic.twitter.com/CwO6f13xp4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanders1016[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren0808 = pd.read_csv('csv/warren0808.csv')['text']\n",
    "warren0815 = pd.read_csv('csv/warren0815.csv')['text']\n",
    "warren0827 = pd.read_csv('csv/warren0827.csv')['text']\n",
    "warren0907 = pd.read_csv('csv/warren0907.csv')['text']\n",
    "warren0911 = pd.read_csv('csv/warren0911.csv')['text']\n",
    "warren0912 = pd.read_csv('csv/warren0912.csv')['text']\n",
    "warren0917 = pd.read_csv('csv/warren0917.csv')['text']\n",
    "warren0921 = pd.read_csv('csv/warren0921.csv')['text']\n",
    "warren0924 = pd.read_csv('csv/warren0924.csv')['text']\n",
    "warren0929 = pd.read_csv('csv/warren0929.csv')['text']\n",
    "warren1003 = pd.read_csv('csv/warren1003.csv')['text']\n",
    "warren1007 = pd.read_csv('csv/warren1007.csv')['text']\n",
    "warren1016 = pd.read_csv('csv/warren1016.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "warrens = [warren0808,warren0815,warren0827,warren0907,warren0911,warren0912,warren0917,warren0921,warren0924,warren0929,warren1003,warren1007,warren1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Warren becomes debate target as moderates vie for breakout: At Tuesday's Democratic presidential debate in Ohio, attacks on Sen. Elizabeth Warren started early and came from all sides, particularly from moreâ€¦ http://dlvr.it/RGLk7R #25thAmendmentNow #ImpeachTrump #TheResistancepic.twitter.com/1nDpcafANn\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warren1016[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation and Analysis\n",
    "\n",
    "The namedate function runs both the get_stats() and get_sentiment() functions, for summary statistics and for sentiment polarity scores, respectively. Then it returns a Numpy array of the summary statistics for all sentiment scores, separated by date. For each candidate, I used a list comprehension to apply the namedate function to each collection of 100 tweets. \n",
    "\n",
    "After this, I reshaped the arrays to have 9 rows, each with 15 items. The original shape was 9,3,5 because the negative, positive, and neutral arrays were still individually separated. To illustrate this point, I am displaying both the sizes of biden_stats (original) and the reshaped biden_np below, followed by the first item in each array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_stats = [namedate(b) for b in bidens]\n",
    "biden_np = np.array(biden_stats).reshape(13,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 3, 5), (13, 15))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(biden_stats).shape, biden_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12768   , 0.125     , 0.        , 0.636     , 0.12656079],\n",
       "       [0.07823   , 0.05      , 0.        , 0.333     , 0.09125797],\n",
       "       [0.79403   , 0.817     , 0.312     , 1.        , 0.14131578]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12768   , 0.125     , 0.        , 0.636     , 0.12656079,\n",
       "       0.07823   , 0.05      , 0.        , 0.333     , 0.09125797,\n",
       "       0.79403   , 0.817     , 0.312     , 1.        , 0.14131578])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren_stats = [namedate(w) for w in warrens]\n",
    "warren_np = np.array(warren_stats).reshape(13,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders_stats = [namedate(s) for s in sanderss]\n",
    "sanders_np = np.array(sanders_stats).reshape(13,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour: Gather data for Tableau visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists to hold positive and negative means\n",
    "b_neg_means = []\n",
    "b_pos_means = []\n",
    "w_neg_means = []\n",
    "w_pos_means = []\n",
    "s_neg_means = []\n",
    "s_pos_means = []\n",
    "\n",
    "for i in range(0,13):\n",
    "    # Index the 2D list to get the 1st and 6th items\n",
    "    # The mean negative scores are always 1st and the mean positive\n",
    "    # scores are always 6th\n",
    "    b_neg_means.append(biden_np[i][0])\n",
    "    b_pos_means.append(biden_np[i][5])\n",
    "    w_neg_means.append(warren_np[i][0])\n",
    "    w_pos_means.append(warren_np[i][5])\n",
    "    s_neg_means.append(sanders_np[i][0])\n",
    "    s_pos_means.append(sanders_np[i][5])\n",
    "\n",
    "# Create DataFrames so that they can be written to csv files using Pandas\n",
    "b_means_df = pd.DataFrame([b_neg_means,b_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24',\n",
    "                                'Sept29','Oct3','Oct7','Oct16'],\n",
    "                       index=['Negative','Positive']).T\n",
    "w_means_df = pd.DataFrame([w_neg_means,w_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24',\n",
    "                                'Sept29','Oct3','Oct7','Oct16'],\n",
    "                       index=['Negative','Positive']).T\n",
    "s_means_df = pd.DataFrame([s_neg_means,s_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24',\n",
    "                                 'Sept29','Oct3','Oct7','Oct16'],\n",
    "                       index=['Negative','Positive']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aug8</th>\n",
       "      <td>0.10073</td>\n",
       "      <td>0.10188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aug15</th>\n",
       "      <td>0.06788</td>\n",
       "      <td>0.13062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aug27</th>\n",
       "      <td>0.08026</td>\n",
       "      <td>0.10900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept7</th>\n",
       "      <td>0.08866</td>\n",
       "      <td>0.13287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept11</th>\n",
       "      <td>0.06112</td>\n",
       "      <td>0.11366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept12</th>\n",
       "      <td>0.07130</td>\n",
       "      <td>0.09764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept17</th>\n",
       "      <td>0.07877</td>\n",
       "      <td>0.10619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept21</th>\n",
       "      <td>0.09815</td>\n",
       "      <td>0.09444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept24</th>\n",
       "      <td>0.04136</td>\n",
       "      <td>0.09838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept29</th>\n",
       "      <td>0.08754</td>\n",
       "      <td>0.09469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct3</th>\n",
       "      <td>0.09917</td>\n",
       "      <td>0.08078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct7</th>\n",
       "      <td>0.13376</td>\n",
       "      <td>0.08803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct16</th>\n",
       "      <td>0.11696</td>\n",
       "      <td>0.07630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Negative  Positive\n",
       "Aug8     0.10073   0.10188\n",
       "Aug15    0.06788   0.13062\n",
       "Aug27    0.08026   0.10900\n",
       "Sept7    0.08866   0.13287\n",
       "Sept11   0.06112   0.11366\n",
       "Sept12   0.07130   0.09764\n",
       "Sept17   0.07877   0.10619\n",
       "Sept21   0.09815   0.09444\n",
       "Sept24   0.04136   0.09838\n",
       "Sept29   0.08754   0.09469\n",
       "Oct3     0.09917   0.08078\n",
       "Oct7     0.13376   0.08803\n",
       "Oct16    0.11696   0.07630"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_means_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Pandas DataFrames to csv files for Tableau\n",
    "b_means_df.to_csv('b_means.csv')\n",
    "w_means_df.to_csv('w_means.csv')\n",
    "s_means_df.to_csv('s_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate Poll Order\n",
    "\n",
    "The poll orderings are as follows:\n",
    "\n",
    "* August 8 via SurveyUSA: \n",
    "    Biden, Sanders, Warren\n",
    "    \n",
    "* August 15 order for likely voters via Fox News: \n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* August 27 LV via Emerson College: \n",
    "    Biden, Sanders, Warren\n",
    "    \n",
    "* September 7 LV via Suffolk University: \n",
    "    Biden, Sanders, Warren \n",
    "    \n",
    "* September 11 via RKM Research and Communications Inc.: \n",
    "    Sanders, Biden, Warren\n",
    "    \n",
    "* September 12 LV via YouGov: \n",
    "    Biden, Warren, Sanders \n",
    "    \n",
    "* September 17 LV via NBC News/Wall Street Journal: \n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* September 21 LV via Selzer and Co: \n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* September 24 LV via Monmouth University: \n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* September 29 LV via CNN/SSRS:\n",
    "    Biden, Warren, Sanders\n",
    "\n",
    "* October 3rd LV via Public Policy Institute of California:\n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* October 7th LV via Morning Consult:\n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* October 16th LV via YouGov:\n",
    "    Warren, Biden, Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One array per candidate in chronological order\n",
    "# 0 = 1st place; 1 = 2nd place; 2 = 3rd place\n",
    "\n",
    "b_target = np.array([0,0,0,0,1,0,0,1,1,0,1,0,1])\n",
    "s_target = np.array([1,2,1,1,0,2,2,2,2,2,2,2,2])\n",
    "w_target = np.array([2,1,2,2,2,1,1,0,0,1,0,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a train/test split for each candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BX_train, BX_test, by_train, by_test = train_test_split(biden_np, b_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_train, WX_test, wy_train, wy_test = train_test_split(warren_np, w_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SX_train, SX_test, sy_train, sy_test = train_test_split(sanders_np, s_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = GaussianNB()\n",
    "clf_linsvc = LinearSVC()\n",
    "clf_dt = tree.DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=3)\n",
    "clf_nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "One problem I ran into here is that, for Sanders, 3-fold cross validation generates a warning because the least-populated class has fewer than 3 items. I originally adjusted for this warning, but the accuracy was better when I proceeded with 3-fold despite the warning message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_crossval = [stat.mean(cross_val_score(clf_nb, biden_np, b_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, biden_np, b_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, biden_np, b_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, biden_np, b_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, biden_np, b_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.511111\n",
       "Linear SVC                             0.622222\n",
       "Decision Tree                          0.444444\n",
       "K-Nearest Neighbors                    0.488889\n",
       "Neural Network                         0.555556"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(b_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "s_crossval = [stat.mean(cross_val_score(clf_nb, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, sanders_np, s_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.416667\n",
       "Linear SVC                             0.700000\n",
       "Decision Tree                          0.383333\n",
       "K-Nearest Neighbors                    0.533333\n",
       "Neural Network                         0.566667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_crossval = [stat.mean(cross_val_score(clf_nb, warren_np, w_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, warren_np, w_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, warren_np, w_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, warren_np, w_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, warren_np, w_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.388889\n",
       "Linear SVC                             0.388889\n",
       "Decision Tree                          0.250000\n",
       "K-Nearest Neighbors                    0.277778\n",
       "Neural Network                         0.388889"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(w_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the best performing classifiers overall are Naive Bayes, Linear SVC, and the Neural Network, while the worst performing classifier overall was the Decision Tree model. \n",
    "\n",
    "* Biden: The Linear SVC outperforms all other models, followed by the Neural Network, then Naive Bayes. K-Nearest Neighbors performed slightly worse and the Decision Tree classifier performed worst of all.\n",
    "* Sanders: The Linear SVC far outperforms all other models, followed by the Neural Network. Lagging behind are the Naive Bayes classifier, then the KNN classifier. In last place is the Decision Tree classifier.\n",
    "* Warren: The Neural Network and Naive Bayes classifiers performed best, followed by the Decision Tree classifier. This was the only instance where the Decision Tree outperformed another model, let alone two. Linear SVC was not far behind the Decision Tree classifier and KNN performed worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(BX_train,by_train)\n",
    "predict_lin_b = clf_linsvc.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_lin_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(BX_train,by_train)\n",
    "predict_nb_b = clf_nb.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_nb_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(BX_train,by_train)\n",
    "predict_nn_b = clf_nn.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_nn_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(SX_train,sy_train)\n",
    "predict_lin_s = clf_linsvc.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_lin_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(SX_train,sy_train)\n",
    "predict_nb_s = clf_nb.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_nb_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(SX_train,sy_train)\n",
    "predict_nn_s = clf_nn.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_nn_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(WX_train,wy_train)\n",
    "predict_lin_w = clf_linsvc.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_lin_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(WX_train,wy_train)\n",
    "predict_nb_w = clf_nb.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_nb_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(WX_train,wy_train)\n",
    "predict_nn_w = clf_nn.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_nn_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation findings\n",
    "None of the learning algorithms perform particularly well, indicating that there is not a strong link between Twitter sentiment and opinion polls. The two populations have mostly different opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Although the populations do not agree well (and thus, any predictions based on a relationship between the two populations are not particularly reliable), I thought it was worth generating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction consensus\n",
    "\n",
    "Most models place Warren in 1st, Biden in 2nd, and Sanders in 3rd. I find it interesting that the Linear SVC placed Warren in either 1st or 3rd place, but the mean accuracy of this model is only about 30%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
