{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This project was started because I was curious how different populations view the top three Democratic presidential candidates. Joe Biden, Bernie Sanders, and Elizabeth Warren consistently poll as the top three, but not always in the same order. \n",
    "Prior to the creation of this notebook, tweets were gathered using [GetOldTweets3](https://pypi.org/project/GetOldTweets3/). This was accomplished using the shell scripts found in the /shellscripts folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "Below are the library imports, functions, and data imports that make this project possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyData\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vader sentiment analyzer from NLTK\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics library\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn imports for ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "I defined three functions to streamline the process of gathering and analyzing sentiment polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get mean, median, min, max, and standard deviation of input\n",
    "def get_stats(info):\n",
    "    me = stat.mean(info)\n",
    "    med = stat.median(info)\n",
    "    mini = min(info)\n",
    "    maxi = max(info)\n",
    "    sdev = stat.stdev(info)\n",
    "    \n",
    "    return me,med,mini,maxi,sdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment polarities\n",
    "def get_sentiment(tweets):\n",
    "    # Lists for each category of sentiment polarity\n",
    "    neg = [] # negative\n",
    "    pos = [] # positive\n",
    "    neu = [] # neutral\n",
    "    \n",
    "    # Run the sentiment intensity analysis for input\n",
    "    for t in tweets:\n",
    "        # Get polarity scores for each tweet\n",
    "        tmp_sia = analyzer.polarity_scores(t)\n",
    "        # Variable assignment for the negative, positive, \n",
    "        # and neutral scores\n",
    "        tmp_neg = tmp_sia['neg']\n",
    "        tmp_pos = tmp_sia['pos']\n",
    "        tmp_neu = tmp_sia['neu']\n",
    "        \n",
    "        # Append each tweet's neg, pos,and neu scores to\n",
    "        # their respective lists\n",
    "        neg.append(tmp_neg)\n",
    "        pos.append(tmp_pos)\n",
    "        neu.append(tmp_neu)\n",
    "    \n",
    "    # Return the lists\n",
    "    return neg,pos,neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function to take in tweets from each date, get\n",
    "the sentiment scores, and get summary statistics \n",
    "from those sentiment scores.'''\n",
    "\n",
    "def namedate(namedate):\n",
    "    # Create a list of lists for sentiments\n",
    "    tmp = [get_sentiment(namedate)]\n",
    "    # Get summary stats \n",
    "    tmp_neg = get_stats(tmp[0][0])\n",
    "    tmp_pos = get_stats(tmp[0][1])\n",
    "    tmp_neu = get_stats(tmp[0][2])\n",
    "    # Make a list of lists for all summary stats\n",
    "    tmp_sents = [tmp_neg,tmp_pos,tmp_neu]\n",
    "    # Convert to numpy array\n",
    "    sents = np.array(tmp_sents)\n",
    "    # Return the converted numpy array\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "There are 13 different dates being analyzed and each candidate has one .csv file per date. After using Pandas to read in the .csv files, I consolidated all input into one array per candidate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden0808 = pd.read_csv('csv/biden0808.csv')['text']\n",
    "biden0815 = pd.read_csv('csv/biden0815.csv')['text']\n",
    "biden0827 = pd.read_csv('csv/biden0827.csv')['text']\n",
    "biden0907 = pd.read_csv('csv/biden0907.csv')['text']\n",
    "biden0911 = pd.read_csv('csv/biden0911.csv')['text']\n",
    "biden0912 = pd.read_csv('csv/biden0912.csv')['text']\n",
    "biden0917 = pd.read_csv('csv/biden0917.csv')['text']\n",
    "biden0921 = pd.read_csv('csv/biden0921.csv')['text']\n",
    "biden0924 = pd.read_csv('csv/biden0924.csv')['text']\n",
    "biden0929 = pd.read_csv('csv/biden0929.csv')['text']\n",
    "biden1003 = pd.read_csv('csv/biden1003.csv')['text']\n",
    "biden1007 = pd.read_csv('csv/biden1007.csv')['text']\n",
    "biden1016 = pd.read_csv('csv/biden1016.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Obama Endorses Justin Trudeau. He Still Hasn’t Endorsed Joe Biden - https://go.shr.lc/35E6gEF'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden1016[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidens = [biden0808,biden0815,biden0827,biden0907,biden0911,biden0912,biden0917,biden0921,biden0924,biden0929,biden1003,biden1007,biden1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders0808 = pd.read_csv('csv/sanders0808.csv')['text']\n",
    "sanders0815 = pd.read_csv('csv/sanders0815.csv')['text']\n",
    "sanders0827 = pd.read_csv('csv/sanders0827.csv')['text']\n",
    "sanders0907 = pd.read_csv('csv/sanders0907.csv')['text']\n",
    "sanders0911 = pd.read_csv('csv/sanders0911.csv')['text']\n",
    "sanders0912 = pd.read_csv('csv/sanders0912.csv')['text']\n",
    "sanders0917 = pd.read_csv('csv/sanders0917.csv')['text']\n",
    "sanders0921 = pd.read_csv('csv/sanders0921.csv')['text']\n",
    "sanders0924 = pd.read_csv('csv/sanders0924.csv')['text']\n",
    "sanders0929 = pd.read_csv('csv/sanders0929.csv')['text']\n",
    "sanders1003 = pd.read_csv('csv/sanders1003.csv')['text']\n",
    "sanders1007 = pd.read_csv('csv/sanders1007.csv')['text']\n",
    "sanders1016 = pd.read_csv('csv/sanders1016.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanderss = [sanders0808,sanders0815,sanders0827,sanders0907,sanders0911,sanders0912,sanders0917,sanders0921,sanders0924,sanders0929,sanders1003,sanders1007,sanders1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BREAKING NEWS FROM WASHINGTON DC QUESTIONS NEED TO BE ANSWERED REGARDING MIKE PENCE AN CAIR MUSLIM BROTHERHOOD WHY WOULD MIKE PENCE BRING SOMEONE TO WASHINGTON DC TIED TO JOE BIDEN.. BERNIE SANDERS.. PLUS THEY HATE PRESIDENT TRUMP. THE QUESTION IS WHY \\u2066 @realDonaldTrump\\u2069pic.twitter.com/CwO6f13xp4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanders1016[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren0808 = pd.read_csv('csv/warren0808.csv')['text']\n",
    "warren0815 = pd.read_csv('csv/warren0815.csv')['text']\n",
    "warren0827 = pd.read_csv('csv/warren0827.csv')['text']\n",
    "warren0907 = pd.read_csv('csv/warren0907.csv')['text']\n",
    "warren0911 = pd.read_csv('csv/warren0911.csv')['text']\n",
    "warren0912 = pd.read_csv('csv/warren0912.csv')['text']\n",
    "warren0917 = pd.read_csv('csv/warren0917.csv')['text']\n",
    "warren0921 = pd.read_csv('csv/warren0921.csv')['text']\n",
    "warren0924 = pd.read_csv('csv/warren0924.csv')['text']\n",
    "warren0929 = pd.read_csv('csv/warren0929.csv')['text']\n",
    "warren1003 = pd.read_csv('csv/warren1003.csv')['text']\n",
    "warren1007 = pd.read_csv('csv/warren1007.csv')['text']\n",
    "warren1016 = pd.read_csv('csv/warren1016.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "warrens = [warren0808,warren0815,warren0827,warren0907,warren0911,warren0912,warren0917,warren0921,warren0924,warren0929,warren1003,warren1007,warren1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Warren becomes debate target as moderates vie for breakout: At Tuesday's Democratic presidential debate in Ohio, attacks on Sen. Elizabeth Warren started early and came from all sides, particularly from more… http://dlvr.it/RGLk7R #25thAmendmentNow #ImpeachTrump #TheResistancepic.twitter.com/1nDpcafANn\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warren1016[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation and Analysis\n",
    "\n",
    "The namedate function runs both the get_stats() and get_sentiment() functions, for summary statistics and for sentiment polarity scores, respectively. Then it returns a Numpy array of the summary statistics for all sentiment scores, separated by date. For each candidate, I used a list comprehension to apply the namedate function to each collection of 100 tweets. \n",
    "\n",
    "After this, I reshaped the arrays to have 9 rows, each with 15 items. The original shape was 9,3,5 because the negative, positive, and neutral arrays were still individually separated. To illustrate this point, I am displaying both the sizes of biden_stats (original) and the reshaped biden_np below, followed by the first item in each array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_stats = [namedate(b) for b in bidens]\n",
    "biden_np = np.array(biden_stats).reshape(13,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 3, 5), (13, 15))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(biden_stats).shape, biden_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12768   , 0.125     , 0.        , 0.636     , 0.12656079],\n",
       "       [0.07823   , 0.05      , 0.        , 0.333     , 0.09125797],\n",
       "       [0.79403   , 0.817     , 0.312     , 1.        , 0.14131578]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12768   , 0.125     , 0.        , 0.636     , 0.12656079,\n",
       "       0.07823   , 0.05      , 0.        , 0.333     , 0.09125797,\n",
       "       0.79403   , 0.817     , 0.312     , 1.        , 0.14131578])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren_stats = [namedate(w) for w in warrens]\n",
    "warren_np = np.array(warren_stats).reshape(13,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders_stats = [namedate(s) for s in sanderss]\n",
    "sanders_np = np.array(sanders_stats).reshape(13,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour: Gather data for Tableau visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists to hold positive and negative means\n",
    "b_neg_means = []\n",
    "b_pos_means = []\n",
    "w_neg_means = []\n",
    "w_pos_means = []\n",
    "s_neg_means = []\n",
    "s_pos_means = []\n",
    "\n",
    "for i in range(0,13):\n",
    "    # Index the 2D list to get the 1st and 6th items\n",
    "    # The mean negative scores are always 1st and the mean positive\n",
    "    # scores are always 6th\n",
    "    b_neg_means.append(biden_np[i][0])\n",
    "    b_pos_means.append(biden_np[i][5])\n",
    "    w_neg_means.append(warren_np[i][0])\n",
    "    w_pos_means.append(warren_np[i][5])\n",
    "    s_neg_means.append(sanders_np[i][0])\n",
    "    s_pos_means.append(sanders_np[i][5])\n",
    "\n",
    "# Create DataFrames so that they can be written to csv files using Pandas\n",
    "b_means_df = pd.DataFrame([b_neg_means,b_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24',\n",
    "                                'Sept29','Oct3','Oct7','Oct16'],\n",
    "                       index=['Negative','Positive']).T\n",
    "w_means_df = pd.DataFrame([w_neg_means,w_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24',\n",
    "                                'Sept29','Oct3','Oct7','Oct16'],\n",
    "                       index=['Negative','Positive']).T\n",
    "s_means_df = pd.DataFrame([s_neg_means,s_pos_means],\n",
    "                        columns=['Aug8','Aug15',\n",
    "                                 'Aug27','Sept7',\n",
    "                                 'Sept11','Sept12',\n",
    "                                'Sept17','Sept21','Sept24',\n",
    "                                 'Sept29','Oct3','Oct7','Oct16'],\n",
    "                       index=['Negative','Positive']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aug8</th>\n",
       "      <td>0.10073</td>\n",
       "      <td>0.10188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aug15</th>\n",
       "      <td>0.06788</td>\n",
       "      <td>0.13062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aug27</th>\n",
       "      <td>0.08026</td>\n",
       "      <td>0.10900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept7</th>\n",
       "      <td>0.08866</td>\n",
       "      <td>0.13287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept11</th>\n",
       "      <td>0.06112</td>\n",
       "      <td>0.11366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept12</th>\n",
       "      <td>0.07130</td>\n",
       "      <td>0.09764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept17</th>\n",
       "      <td>0.07877</td>\n",
       "      <td>0.10619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept21</th>\n",
       "      <td>0.09815</td>\n",
       "      <td>0.09444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept24</th>\n",
       "      <td>0.04136</td>\n",
       "      <td>0.09838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sept29</th>\n",
       "      <td>0.08754</td>\n",
       "      <td>0.09469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct3</th>\n",
       "      <td>0.09917</td>\n",
       "      <td>0.08078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct7</th>\n",
       "      <td>0.13376</td>\n",
       "      <td>0.08803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct16</th>\n",
       "      <td>0.11696</td>\n",
       "      <td>0.07630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Negative  Positive\n",
       "Aug8     0.10073   0.10188\n",
       "Aug15    0.06788   0.13062\n",
       "Aug27    0.08026   0.10900\n",
       "Sept7    0.08866   0.13287\n",
       "Sept11   0.06112   0.11366\n",
       "Sept12   0.07130   0.09764\n",
       "Sept17   0.07877   0.10619\n",
       "Sept21   0.09815   0.09444\n",
       "Sept24   0.04136   0.09838\n",
       "Sept29   0.08754   0.09469\n",
       "Oct3     0.09917   0.08078\n",
       "Oct7     0.13376   0.08803\n",
       "Oct16    0.11696   0.07630"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_means_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Pandas DataFrames to csv files for Tableau\n",
    "b_means_df.to_csv('b_means.csv')\n",
    "w_means_df.to_csv('w_means.csv')\n",
    "s_means_df.to_csv('s_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate Poll Order\n",
    "\n",
    "The poll orderings are as follows:\n",
    "\n",
    "* August 8 via SurveyUSA: \n",
    "    Biden, Sanders, Warren\n",
    "    \n",
    "* August 15 order for likely voters via Fox News: \n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* August 27 LV via Emerson College: \n",
    "    Biden, Sanders, Warren\n",
    "    \n",
    "* September 7 LV via Suffolk University: \n",
    "    Biden, Sanders, Warren \n",
    "    \n",
    "* September 11 via RKM Research and Communications Inc.: \n",
    "    Sanders, Biden, Warren\n",
    "    \n",
    "* September 12 LV via YouGov: \n",
    "    Biden, Warren, Sanders \n",
    "    \n",
    "* September 17 LV via NBC News/Wall Street Journal: \n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* September 21 LV via Selzer and Co: \n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* September 24 LV via Monmouth University: \n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* September 29 LV via CNN/SSRS:\n",
    "    Biden, Warren, Sanders\n",
    "\n",
    "* October 3rd LV via Public Policy Institute of California:\n",
    "    Warren, Biden, Sanders\n",
    "    \n",
    "* October 7th LV via Morning Consult:\n",
    "    Biden, Warren, Sanders\n",
    "    \n",
    "* October 16th LV via YouGov:\n",
    "    Warren, Biden, Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One array per candidate in chronological order\n",
    "# 0 = 1st place; 1 = 2nd place; 2 = 3rd place\n",
    "\n",
    "b_target = np.array([0,0,0,0,1,0,0,1,1,0,1,0,1])\n",
    "s_target = np.array([1,2,1,1,0,2,2,2,2,2,2,2,2])\n",
    "w_target = np.array([2,1,2,2,2,1,1,0,0,1,0,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a train/test split for each candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BX_train, BX_test, by_train, by_test = train_test_split(biden_np, b_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_train, WX_test, wy_train, wy_test = train_test_split(warren_np, w_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SX_train, SX_test, sy_train, sy_test = train_test_split(sanders_np, s_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = GaussianNB()\n",
    "clf_linsvc = LinearSVC()\n",
    "clf_dt = tree.DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=3)\n",
    "#clf_nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf_nn = MLPClassifier(solver='lbfgs', alpha=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the neural network, the LBFGS solver is chosen because, \"For small datasets, however, ‘lbfgs’ can converge faster and perform better\" than other solvers, such as the defualt 'adam'. This quote is taken from scikit-learn documentation. This documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "One problem I ran into here is that, for Sanders, 3-fold cross validation generates a warning because the least-populated class has fewer than 3 items. I originally adjusted for this warning, but the accuracy was better when I proceeded with 3-fold despite the warning message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_crossval = [stat.mean(cross_val_score(clf_nb, biden_np, b_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, biden_np, b_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, biden_np, b_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, biden_np, b_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, biden_np, b_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.511111\n",
       "Linear SVC                             0.622222\n",
       "Decision Tree                          0.200000\n",
       "K-Nearest Neighbors                    0.488889\n",
       "Neural Network                         0.622222"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(b_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "s_crossval = [stat.mean(cross_val_score(clf_nb, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, sanders_np, s_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, sanders_np, s_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.416667\n",
       "Linear SVC                             0.700000\n",
       "Decision Tree                          0.450000\n",
       "K-Nearest Neighbors                    0.533333\n",
       "Neural Network                         0.700000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_crossval = [stat.mean(cross_val_score(clf_nb, warren_np, w_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_linsvc, warren_np, w_target, cv=3)),\n",
    "              stat.mean(cross_val_score(clf_dt, warren_np, w_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_knn, warren_np, w_target,cv=3)),\n",
    "              stat.mean(cross_val_score(clf_nn, warren_np, w_target,cv=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg 3-fold cross-val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Avg 3-fold cross-val score\n",
       "Naive Bayes                            0.388889\n",
       "Linear SVC                             0.305556\n",
       "Decision Tree                          0.361111\n",
       "K-Nearest Neighbors                    0.277778\n",
       "Neural Network                         0.388889"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(w_crossval,index=['Naive Bayes','Linear SVC','Decision Tree','K-Nearest Neighbors','Neural Network'],columns=['Avg 3-fold cross-val score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the best performing classifiers overall are Linear SVC and the Neural Network. Naive Bayes was moderately successful for all candidates, but the KNN model performed similarly well. The least accurate model overall was the Decision Tree model. However, this was not true for Warren and the DT model's efficacy is not far behind the others for Biden and Sanders.\n",
    "\n",
    "* Biden: At the time of my video presentation, I was getting the result that the Linear SVC outperforms all other models, followed by the Neural Network, then Naive Bayes. K-Nearest Neighbors performed slightly worse and the Decision Tree classifier performed worst of all. However, as I added final comments to this file, I realized that I had not fine-tuned all of the parameters for the neural network. I do not recall the source of the original parameters, which is an ethical misstep. As such, I updated the parameters. This increased the efficacy of the Neural Network and now it matches the average accuracy of the Linear SVC classifier. Naive Bayes is still the third most accurate, on average.\n",
    "\n",
    "\n",
    "* Sanders: Again, at the time of the video presentation I had different results. At that time, the Linear SVC far outperfomeds all other models, followed by the Neural Network. After the update, the Neural Network is equally successful. Previously, the KNN classifier was fourth, but it has swapped places with Naive Bayes. I do not believe that adjusting the Neural Network parameters should have affected the KNN classifier, so I am unsure what caused this shift. I cleared the kernel before I re-ran all cells, so this is not a vestigial result. Still in last place is the Decision Tree classifier.\n",
    "\n",
    "\n",
    "* Warren: This iteration, the Naive Bayes classifier and the Neural Networks were the only ones to reach the average 38.89% accuracy previously shown by all three of the following: the Neural Network classifier, Naive Bayes classifier, and Linear SVC. The Linear SVC is now fourth. Prior to the paramater tuning of the Neural Network, the Naive Bayes classifier, Linear SVC, and Neural Network classifier were followed by the KNN classifier, then the Decision Tree classifier. Now the Decision Tree is the second best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(BX_train,by_train)\n",
    "predict_lin_b = clf_linsvc.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_lin_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(BX_train,by_train)\n",
    "predict_nb_b = clf_nb.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_nb_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(BX_train,by_train)\n",
    "predict_nn_b = clf_nn.predict(BX_test)\n",
    "confusion_matrix(by_test,predict_nn_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model for Biden, Linear SVC, had only 2 correct predictions, both true positives. It had 2 false negatives and one false positive.\n",
    "\n",
    "The tied-for-first model, the Neural Network, had better results. It had 4 correct predictions (80% success) and one false positive.\n",
    "\n",
    "The third-place model, Naive Bayes, only had 1 correct result, with 1 true negative and 4 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvc.fit(SX_train,sy_train)\n",
    "predict_lin_s = clf_linsvc.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_lin_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [2, 0, 2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn.fit(SX_train,sy_train)\n",
    "predict_knn_s = clf_knn.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_knn_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(SX_train,sy_train)\n",
    "predict_nn_s = clf_nn.predict(SX_test)\n",
    "confusion_matrix(sy_test,predict_nn_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing models for Sanders were also the Linear SVC and Neural Network. In Sanders' case, they both got 4 correct predictions, all true negatives. The remaining prediction for both was a false negative. Thus, 80% of the predictions were accurate, as opposed to the 70% found by the cross-validated model.\n",
    "\n",
    "Sanders' data had KNN as its third place model. It had a 53.33% average accuracy. Here, it performed somewhat worse, with a 40% success rate, with 2 correct predictions and 3 incorrect. Because the number of neighbors was set to 3, this matrix is 3x3 instead of 2x2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(WX_train,wy_train)\n",
    "predict_nb_w = clf_nb.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_nb_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes was the most accurate model on average, with an average success rate of almost 40%. Here it was only 20% accurate (1 out of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.fit(WX_train,wy_train)\n",
    "predict_dt_w = clf_dt.predict(WX_test)\n",
    "confusion_matrix(wy_test, predict_dt_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree was the second best at around a 36% average accuracy. Here, it performed better than the Naive Bayes classifier, as it was 40% accurate. These results are more similar than the results of the NB classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 3],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.fit(WX_train,wy_train)\n",
    "predict_nn_w = clf_nn.predict(WX_test)\n",
    "confusion_matrix(wy_test,predict_nn_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network was tied for first, with an average accuracy of 38.89%. Here, 20% of the predictions (1/5) were correct. This was a surprising discrepancy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warren has particularly interesting predictions because she has polled in 1st, 2nd, and 3rd place. I believe this made it harder for the models to predict her poll order. Through cross-validation, the most accurate models were shown to be Naive Bayes and the Neural Network, followed by Decision Tree in third."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation findings\n",
    "For Warren and Biden, none of the learning algorithms perform particularly well, indicating that there is not a strong correlation between Twitter sentiment and opinion polls. There is a stronger correlation for Biden than for Warren, as his best model had an average 62.2% accuracy when cross-validated. The only candidate with decent predictions was Sanders, with one prediction showing an 80% success. This anomaly will be explored by investigating the predictions for the testing set. Overall, I conclude that the two populations don't have strongly correlating opinions, i.e. are distinct in their opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Above, I explained that the populations do not agree strongly and thus any predictions based on a relationship between the two populations are not particularly reliable. Still, as stated, I want to determine if there is a reason for Sanders' predictions of the testing set being more successful. I will explore the predictions for the other candidates as well and interpret the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear SVC has mixed predictons. The average accuracy of this model was only about 60%, but the iteration with predictions found an 80% success rate. Of course, this is only an average, so the 80% result is not necessarily a typical result. These results are thus semi-reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, all of the predictions are the same. Of course, this model only had an approximately 50% success rate. I will partially attribute this result to Naive Bayes' high bias and low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network, in the example shown, had an 80% success. Here all of the predictions are the same, as they are in the Naive Bayes approach. However, I am more confident in these predictions to the example success rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of Biden's models gave the same predictions, so it is not surprising that they had mixed results for their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "predict_lin_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Sanders, the Linear SVC had an average accuracy of 70%, as did the Neural Network. In the predictions, both had an 80% success. This is less of an anomaly than the 80% for Biden, mentioned above. I would consider these predictions to be reasonably reliable. This means that both moderately successful models place Sanders third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_knn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN had an average accuracy of slightly over 50%, while the predictions only had a 40% success rate. It is not surprising that this prediction is inconsistent with the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, these predictions were equally as successful as the Linear SVC and equally as reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "predict_dt_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "predict_nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "predict_nn_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction consensus\n",
    "\n",
    "Most models place Warren or Biden in 1st, and Sanders in 3rd.\n",
    "\n",
    "I find it interesting that the Neural Network placed Warren in either 1st or 3rd place, as did the DT. For Warren, 9/15 predictions across the three models put her in 1st place, or 60% of predictions. 6/15 placed her in 3rd, or 40%.\n",
    "\n",
    "Biden had 8/15 predictions across the three models that he would be in 1st place. This is 53.33% of predictions. Warren is placed in 1st more often than Biden.\n",
    "\n",
    "Sanders was predicted in 1st only twice, or 13.33% of the time. He came in 3rd the remaining 86.67% percent of the time. Since Sanders' input/target is the most consistent, it's not surprising that these were the most successful predictions. This was true on average and shown even more strongly with these specific predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not believe that the predictions herein can be considered fully reliable, but there are some slight correlations shown. These correlations can be compared to those uncovered by the Tableau viz, found [here](https://public.tableau.com/profile/emma.highland#!/vizhome/MSDS692/Pollcomparison). I found that less of a correlation is shown in the Tableau viz than shown here. The visualized time series only shows a pattern (an inverse correlation) with Warren, where the Twitter sentiments become less positive over time, while her poll order rises. Sanders has stagnated in his poll ordering, as shown here as well with the consistency of his 3rd place prediction. His sentiment scores have become slightly more positive over time, but I would have expected the positive sentiment to correlate with rising poll order. This did not occur. Biden goes through patches of more positive and more negative sentiments, but this does not correlate positively or negatively with the changes in his poll order. He has only vacillated between 1st and 2nd, rather than the range and rise shown by Warren.\n",
    "\n",
    "I conclude that the populations (poll takers and randomly-chosen Twitter users) have distinct opinions that do not follow the same trend. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
